# ExtractCode Inputs
vulnerability_limit: 10
context_size: 1000
# sari_file_path should point to the generated SARIF file relative to the working directory
# sarif_file_path: /mnt/data/sarif.json

# PreparePrompt Inputs
# prompt_template_file: your-prompt-template-here

# CallOpenAI Inputs
# openai_api_key: required
openai_api_key: no_key_open_source_local
model: llama-3-8B
client_base_url: http://localhost:8000/v1
#model: gpt-3.5-turbo
# client_base_url: http://localhost:8000/v1
github_api_key: your-api-key
# Example HF model
# client_base_url: https://api-inference.huggingface.co/models/meta-llama/Meta-Llama-3-70B-Instruct/v1
# model: meta-llama/Meta-Llama-3-70B-Instruct
# model_temperature: 0.2
# model_top_p: 0.95
# model_max_tokens: 2000
allow_truncated: false

# CommitChanges Inputs
disable_branch: false

# CreatePR Inputs
disable_pr: false
force_pr_creation: true
# github_api_key: required-for-github-scm
# gitlab_api_key: required-for-gitlab-scm